---
title: Tutorial at PReMI 2025 - Beyond Transformers - Deep Dive into Mamba and SSMs

event: 11th International Conference on Pattern Recognition and Machine Intelligence (PReMI 2025)
event_url: https://premi25.iitd.ac.in/

location: IIT Delhi, India
summary: Tutorial session on state space models (SSMs) and Mamba architecture as alternatives to transformer models for sequence modeling.

# Talk start and end times.
date: '2025-12-11T09:00:00Z'
date_end: '2025-12-11T12:30:00Z'
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: '2025-12-01T00:00:00Z'

authors: []
tags: [Mamba, SSM, State Space Models, Transformers, Deep Learning, Sequence Modeling]

# Is this a featured talk? (true/false)
featured: true

links:
  - name: Conference
    url: https://premi25.iitd.ac.in
url_code: ''
url_pdf: ''
url_slides: ''
url_video: ''

projects: []
---

**Tutorial: Beyond Transformers - Deep Dive into Mamba and State Space Models**

Presented at the 11th International Conference on Pattern Recognition and Machine Intelligence (PReMI 2025), IIT Delhi.

This tutorial session explored:
- State Space Models (SSMs) fundamentals and evolution
- Mamba architecture - a linear-time sequence modeling alternative to transformers
- Selective state spaces and their advantages
- Comparison of SSMs vs Transformers for various sequence modeling tasks
- Nemotron Nanov3

PReMI 2025 brought together researchers and practitioners in pattern recognition, machine intelligence, and related fields from across the globe.

**Conference Date:** December 11-14, 2025
**Tutorial Date:** December 11, 2025 (Pre-conference Tutorial Day)
